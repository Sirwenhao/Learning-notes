```
#pytorch廖星宇教程实现自动编码器，生成对抗网络

import os
import torch
from torch import nn,optim
from torch.autograd import Variable
from torchvision import transforms,datasets
from torch.utils.data import DataLoader
import torch.nn.functional as F
from torchvision.utils import save_image

#加载数据集
def get_data():                         //定义函数用于获取数据并进行预处理
    data_tf = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5],[0.5])])    //将数据变为tensor类型，并标准化为：output =  （input - mean）/std，mean各通道的均值，std各通道标准差，inplace判断是否原地操作
    train_data = datasets.MNIST(root='./data',train = True,transform = data_tf,download = False)
    train_loader = DataLoader(train_data,shuffle = True,batch_size = batch_size,drop_last = True)
    return train_loader

class VAE(nn.Module):
    def __init__(self):
        super(VAE, self).__init__()
        self.fc1 = nn.Linear(784,400)
        self.fc21 = nn.Linear(400,20)
        self.fc22 = nn.Linear(400,20)
        self.fc3 = nn.Linear(20,400)
        self.fc4 = nn.Linear(400,784)

    def encoder(self,x):                                         //编码器部分
        h1 = F.relu(self.fc1(x))
        mu = self.fc21(h1)
        logvar = self.fc22(h1)
        return mu,logvar

    def decoder(self,z):                                        //译码器部分
        h3 = F.relu(self.fc3(z))
        x = F.tanh(self.fc4(h3))
        return x

#重新参数化
    def reparametrize(self,mu,logvar):
        std = logvar.mul(0.5).exp_()
        if torch.cuda.is_available():              //Returns a bool indicating if CUDA is currently available.通过布尔值（0或1）判断当前CUDA是否可用
            eps = torch.FloatTensor(std.size()).normal_()
        else:
            eps = torch.FloatTensor(std.size()).normal_()
        eps = Variable(eps)
        return eps.mul(std).add_(mu)

    def forward(self,x):
        mu, logvar = self.encoder(x)
        z = self.reparametrize(mu,logvar)
        return self.decoder(z),mu,logvar

def loss_function(recon_x, x, mu, logvar):
    MSE = reconstruction_function(recon_x, x)
    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)
    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)
    KLD = torch.sum(KLD_element).mul_(-0.5)
    # KL divergence
    return MSE + KLD

def to_img(x):
    x = (x + 1.) * 0.5
    x = x.clamp(0,1)
    x = x.view(x.size(0),1,28,28)
    return x

if __name__ == '__main__':
    #设置超参数
    batch_size = 128
    lr = 1e-3
    epoches = 100

    model = VAE()
    if torch.cuda.is_available():
        model.cuda()

    train_data = get_data()

    reconstruction_function = nn.MSELoss(reduction = 'sum')
    optimizer = optim.Adam(model.parameters(),lr = lr)

    for epoch in range(epoches):
        for img,_ in train_data:
            img = img.view(img.size(0),-1)
            img = Variable(img)
            if torch.cuda.is_available():
                img = img.cuda()

            #forward
            output, mu, logvar = model(img)
            loss = loss_function(output,img,mu,logvar)/img.size(0)
            #backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        print("epoch = ",epoch,loss.data.float())
        if (epoch+1) % 10 == 0:
            print("epoch = {},loss is {}".format(epoch+1,loss.data))
            pic = to_img(output.cpu().data)
            if not os.path.exists('./vae_img1'):
                os.mkdir('./vae_img1')
            save_image(pic, './vae_img1/image_{}.png'.format(epoch + 1))
        torch.save(model, './vae.pth')
```

使用生成对抗网络对MNIST数据集进行训练生成十个效果图。

训练的周期以及细节：

epoch =  0 tensor(85.8181)
epoch =  1 tensor(76.9008)
epoch =  2 tensor(78.7346)
epoch =  3 tensor(69.5263)
epoch =  4 tensor(69.9992)
epoch =  5 tensor(71.4032)
epoch =  6 tensor(72.3483)
epoch =  7 tensor(70.3111)
epoch =  8 tensor(69.7133)
epoch =  9 tensor(69.8316)
epoch = 10,loss is 69.83158874511719
epoch =  10 tensor(70.7941)
epoch =  11 tensor(66.1141)
epoch =  12 tensor(67.1038)
epoch =  13 tensor(68.6337)
epoch =  14 tensor(68.3046)
epoch =  15 tensor(70.1812)
epoch =  16 tensor(67.2724)
epoch =  17 tensor(65.1548)
epoch =  18 tensor(65.9722)
epoch =  19 tensor(66.3036)
epoch = 20,loss is 66.3035888671875
epoch =  20 tensor(68.1798)
epoch =  21 tensor(62.3431)
epoch =  22 tensor(66.0011)
epoch =  23 tensor(64.7142)
epoch =  24 tensor(66.0149)
epoch =  25 tensor(66.5611)
epoch =  26 tensor(65.8893)
epoch =  27 tensor(62.6532)
epoch =  28 tensor(64.5373)
epoch =  29 tensor(65.0956)
epoch = 30,loss is 65.09562683105469
epoch =  30 tensor(65.0400)
epoch =  31 tensor(62.7796)
epoch =  32 tensor(65.2954)
epoch =  33 tensor(65.8283)
epoch =  34 tensor(67.8600)
epoch =  35 tensor(64.1920)
epoch =  36 tensor(60.8901)
epoch =  37 tensor(65.7609)
epoch =  38 tensor(64.6742)
epoch =  39 tensor(66.1637)
epoch = 40,loss is 66.16368865966797
epoch =  40 tensor(61.2256)
epoch =  41 tensor(66.7449)
epoch =  42 tensor(61.7086)
epoch =  43 tensor(64.6589)
epoch =  44 tensor(63.6687)
epoch =  45 tensor(64.3496)
epoch =  46 tensor(65.0211)
epoch =  47 tensor(65.4958)
epoch =  48 tensor(62.3870)
epoch =  49 tensor(62.9934)
epoch = 50,loss is 62.9933967590332
epoch =  50 tensor(61.4558)
epoch =  51 tensor(62.8174)
epoch =  52 tensor(63.1092)
epoch =  53 tensor(63.1558)
epoch =  54 tensor(66.5956)
epoch =  55 tensor(61.9979)
epoch =  56 tensor(64.8587)
epoch =  57 tensor(62.7145)
epoch =  58 tensor(63.9039)
epoch =  59 tensor(58.3984)
epoch = 60,loss is 58.3984375
epoch =  60 tensor(64.9799)
epoch =  61 tensor(62.4821)
epoch =  62 tensor(66.6185)
epoch =  63 tensor(61.5069)
epoch =  64 tensor(63.4909)
epoch =  65 tensor(65.1996)
epoch =  66 tensor(62.2405)
epoch =  67 tensor(60.2039)
epoch =  68 tensor(63.9786)
epoch =  69 tensor(61.2610)
epoch = 70,loss is 61.26100158691406
epoch =  70 tensor(61.3523)
epoch =  71 tensor(62.3564)
epoch =  72 tensor(63.9952)
epoch =  73 tensor(61.7238)
epoch =  74 tensor(60.5487)
epoch =  75 tensor(61.2299)
epoch =  76 tensor(61.7495)
epoch =  77 tensor(62.5758)
epoch =  78 tensor(64.6937)
epoch =  79 tensor(62.9806)
epoch = 80,loss is 62.98056411743164
epoch =  80 tensor(62.8370)
epoch =  81 tensor(62.1472)
epoch =  82 tensor(59.6793)
epoch =  83 tensor(60.5521)
epoch =  84 tensor(63.7647)
epoch =  85 tensor(58.7541)
epoch =  86 tensor(59.9646)
epoch =  87 tensor(63.6078)
epoch =  88 tensor(60.9856)
epoch =  89 tensor(62.9059)
epoch = 90,loss is 62.90592575073242
epoch =  90 tensor(60.5253)
epoch =  91 tensor(60.6621)
epoch =  92 tensor(62.7363)
epoch =  93 tensor(62.6027)
epoch =  94 tensor(59.4947)
epoch =  95 tensor(59.9732)
epoch =  96 tensor(58.6573)
epoch =  97 tensor(60.1287)
epoch =  98 tensor(63.7270)
epoch =  99 tensor(62.5523)
epoch = 100,loss is 62.552310943603516





![image_10](C:\Users\WH\pythonProject6.1\vae_img1\image_10.png)





![image_20](C:\Users\WH\pythonProject6.1\vae_img1\image_20.png)





![image_30](C:\Users\WH\pythonProject6.1\vae_img1\image_30.png)





![image_40](C:\Users\WH\pythonProject6.1\vae_img1\image_40.png)





![image_50](C:\Users\WH\pythonProject6.1\vae_img1\image_50.png)





![image_60](C:\Users\WH\pythonProject6.1\vae_img1\image_60.png)





<img src="C:\Users\WH\pythonProject6.1\vae_img1\image_70.png" alt="image_70"  />





![image_80](C:\Users\WH\pythonProject6.1\vae_img1\image_80.png)





![image_90](C:\Users\WH\pythonProject6.1\vae_img1\image_90.png)





![image_100](C:\Users\WH\pythonProject6.1\vae_img1\image_100.png)

RMSprop      

Adam优化算法



