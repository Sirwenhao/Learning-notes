# 卷积神经网络：

## 一、VGG-16，VGG-19

1、VGG-16代码：

```
#VGG16的传统方法

#导入包
     
import torch.nn as nn   #vgg中实际使用的pytorch工具



#定义函数结构
class VGG16(nn.Module):    #创建类，类名称为VGG
    def __init__(self,num_classes):    #定义类中的函数，self为形参，函数自身的参数,num_classes为实参
        super(VGG16,self).__init__()   #继承父类VGG16的方法初始化继承到的属性
        self.features = nn.Sequential(  #torch.nn.Sequential()是一个Sequential容器，模块将按照构造函数中传递的顺序添加到模块中。通俗的话说，就是根据自己的需求，把不同的函数组合成一个（小的）模块使用或者把组合的模块添加到自己的网络中。将卷积层池化层传输之后的放到features中。
            #1
            nn.Conv2d(3,64,3,padding = 1),
            nn.ReLU(True),
            #2
            nn.Conv2d(64,64,3,padding = 1),
            nn.ReLU(True),
            nn.MaxPool2d(kernel_size = 3,padding = 2),
            #3
            nn.Conv2d(64,128,3,padding = 1),
            nn.ReLU(True),
            #4
            nn.Conv2d(128,128,3,padding = 1),
            nn.ReLU(True),
            nn.MaxPool2d(kernel_size = 2,padding = 2),
            #5
            nn.Conv2d(128,256,3,padding = 1),
            nn.ReLU(True),
            #6
            nn.Conv2d(256,256,3,padding = 1),
            nn.ReLU(True),
            #7
            nn.Conv2d(256,256,3,padding = 1),
            nn.ReLU(True),
            nn.MaxPool2d(kernel_size = 3,padding = 1),
            #8
            nn.Conv2d(256,512,3,padding = 1),
            nn.ReLU(True),
            #9
            nn.Conv2d(512,512,3, padding = 1),
            nn.ReLU(),
            #10
            nn.Conv2d(512,512,3,padding = 1),
            nn.ReLU(True),
            nn.MaxPool2d(kernel_size = 3,padding = 1),
            #11
            nn.Conv2d(512,512,3,padding = 1),
            nn.ReLU(True),
            #12
            nn.Conv2d(512,512,3,padding = 1),
            nn.ReLU(True),
            #13
            nn.Conv2d(512,512,3,padding = 1),
            nn.ReLU(True),
            nn.MaxPool2d(kernel_size = 3,padding = 1),)

        self.classifier = nn.Sequential(            #定义一个分类器，也是使用Sequential方法，并将全连接层的传递放在classifier中
            #14
            nn.Linear(512,4096),
            nn.ReLU(True),
            #15
            nn.Linear(4096,4096),
            nn.ReLU(True),
            #16
            nn.Linear(4096,num_classes),
        )
    def forward(self,x):                           #定义前向传播，参数为x
        x = self.features(x)                       #将变量x传入到self.features函数中，遍历全连接层和池化层
        #print(x.shape)
        x = x.view(x.size(0),-1)    			  #view是展平函数，将原来features输出的多维Tensor展平为一维
        #print(x.shape)
        x = self.classifier(x)                     #将展平后的x传入到全连接层，进行输出
        print(x.shape)
```

2、VGG-19代码





## 二、 #廖星宇89页,9层简单网络结构

```


#导入包
import torch.nn as nn


#定义网络结构
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.layer1 = nn.Sequential(
            #1
            nn.Conv2d(3,32,3,1,padding = 1),  #in = 3,out = 32,kernel size = 3,stride = 1
            nn.ReLU(True),
            #2
            nn.MaxPool2d(kernel_size = 2,stride = 2),
            #3
            nn.Conv2d(32,64,3,1,padding = 1),
            nn.ReLU(True),
            #4
            nn.MaxPool2d(kernel_size = 2,stride = 2),
            #5
            nn.Conv2d(64,128,3,1,padding = 1),
            nn.ReLU(True),
            #6
            nn.MaxPool2d(kernel_size = 2,stride = 2),

        )
        self.layer2 = nn.Sequential(
            #7
            nn.Linear(2048,512),
            nn.ReLU(True),
            #8
            nn.Linear(512,64),
            nn.ReLU(True),
            #9
            nn.Linear(64,10),
        )
        def forward(self,x):
            x = self.layer1(x)
            x = x.view(x.size[0],-1)   #将卷积层的高维输出展平
            x = self.layer2(x)
            return x

#打印网络结构
net = SimpleCNN()
print(net)
```

